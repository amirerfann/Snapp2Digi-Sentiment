{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d28a732c",
      "metadata": {
        "id": "d28a732c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1bae69fb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bae69fb",
        "outputId": "18f069ae-b2c2-4799-9097-ccf4a96b267d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at HooshvareLab/bert-base-parsbert-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at HooshvareLab/bert-base-parsbert-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\")\n",
        "bert_model = TFAutoModel.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a7145179",
      "metadata": {
        "id": "a7145179"
      },
      "outputs": [],
      "source": [
        "def get_bert_embeddings(texts, tokenizer, model, max_len=64):\n",
        "    embeddings = []\n",
        "    for text in tqdm(texts):\n",
        "        inputs = tokenizer(text, return_tensors='tf', max_length=max_len, truncation=True, padding='max_length')\n",
        "        outputs = model(inputs)[0]  # shape: (1, seq_len, hidden)\n",
        "        cls_vector = outputs[:, 0, :]  # فقط بردار CLS\n",
        "        embeddings.append(cls_vector.numpy()[0])\n",
        "    return np.array(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d36e191c",
      "metadata": {
        "id": "d36e191c"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    # مدل ساده LSTM\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(128, input_shape=(1, 768)))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "058c8d15",
      "metadata": {
        "id": "058c8d15"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"clean_snapp.csv\")\n",
        "texts = df['comment_cleaned'].astype(str).tolist()\n",
        "labels = df['label'].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44b3080a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44b3080a",
        "outputId": "9d47ec69-435e-4de4-e866-eec1d74819dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 438/18508 [01:31<58:50,  5.12it/s]"
          ]
        }
      ],
      "source": [
        "X = get_bert_embeddings(texts, tokenizer, bert_model)\n",
        "y = np.array(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc58d78e",
      "metadata": {
        "id": "cc58d78e"
      },
      "outputs": [],
      "source": [
        "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b86fc851",
      "metadata": {
        "id": "b86fc851"
      },
      "outputs": [],
      "source": [
        "model = create_model()\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# 5. ارزیابی\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", acc)\n",
        "\n",
        "model.save(\"model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26f0b7e9",
      "metadata": {
        "id": "26f0b7e9"
      },
      "outputs": [],
      "source": [
        "digikala_df = pd.read_csv(\"clean_digikala.csv\", encoding='utf-8', quotechar='\"')\n",
        "digikala_texts = digikala_df['comment_cleaned'].astype(str).tolist()\n",
        "digikala_embeds = get_bert_embeddings(digikala_texts, tokenizer, bert_model)\n",
        "digikala_embeds = digikala_embeds.reshape((digikala_embeds.shape[0], 1, 768))\n",
        "predictions = (model.predict(digikala_embeds) > 0.5).astype(int)\n",
        "digikala_df['predicted_label'] = predictions\n",
        "digikala_df['predicted_label'] = digikala_df['predicted_label'].map({1: 'SAD', 0: 'HAPPY'})\n",
        "digikala_df.to_csv(\"outputs/digikala_labeled.csv\", index=False)\n",
        "print(\"Saved predictions to outputs/digikala_labeled.csv\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}